{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\SPARK'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession with necessary configurations\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('Spark') \\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .config(\"spark.hadoop.home.dir\", \"H:/HADOOP/\") \\\n",
    "    .config(\"spark.hadoop.conf.dir\", \"H:/HADOOP/etc/hadoop/\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "import sys\n",
    "sys.path.append(\"G:\\Dissertation_Project\")\n",
    "\n",
    "# Get SparkContext from the SparkSession\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.6:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x13cbce28050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|Conversation_ID|Attacker_Helper                                                                                                                                                 |Victim                                                                                                                                                                                         |Conversation_Type|\n",
      "+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|GT1sURbxgG     |Hi, this is John from the IRS. You owe us $10,000 in back taxes.                                                                                                |I'm sorry, I don't believe you. Can you provide me with your badge number?                                                                                                                     |1                |\n",
      "|GT1sURbxgG     |Yes, of course. It's 1234.                                                                                                                                      |I'm still not sure. Can I call you back to verify this information?                                                                                                                            |1                |\n",
      "|GT1sURbxgG     |No, you cannot. We need payment immediately or we will send the police to your house.                                                                           |I don't think that's legal. I'll be contacting the IRS directly to confirm this.                                                                                                               |1                |\n",
      "|TwaGOeC96w     |Hello, this is XYZ bank calling. May I speak with [Victim's name] please?                                                                                       |This is [Victim's name]. How can I help you?                                                                                                                                                   |0                |\n",
      "|TwaGOeC96w     |Good morning [Victim's name], we just noticed some unusual activity on your account and want to verify a few things. Can you confirm your account number for me?|I'm sorry, I don't feel comfortable giving out my account number on the phone. Is there another way we can verify my information?                                                              |0                |\n",
      "|TwaGOeC96w     |Absolutely, we completely understand your concerns. Can you please provide your date of birth and Social Security number for verification purposes?             |I'm still hesitant to provide that information over the phone. Can I come into the bank and verify my information in person?                                                                   |0                |\n",
      "|TwaGOeC96w     |Of course, that's a great idea. Our branch hours are 9am-5pm, Monday through Friday. Is there a day and time that works best for you?                           |Yes, I can come in on Thursday at around 2pm. Thank you for understanding.                                                                                                                     |0                |\n",
      "|V73ZDCviQL     |Hello sir, this is a call from the IRS. We have found discrepancies in your tax filings and need to verify some information.                                    |I've never had any issues with my taxes before. Can you provide me with more specific information?                                                                                             |1                |\n",
      "|V73ZDCviQL     |Yes sir, we need your social security number and bank account details to verify the information.                                                                |I'm sorry, but I don't feel comfortable sharing that information over the phone. Can you send me an email or mail me a letter instead?                                                         |1                |\n",
      "|V73ZDCviQL     |There's no need to worry sir. We are a legitimate organization and need this information to resolve the issue quickly.                                          |I appreciate your concern, but I still cannot provide that information over the phone. Can you please provide me with a reference number for this issue so I can verify it with the IRS myself?|1                |\n",
      "+---------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_df = spark.read.csv(\"../../Data/Custom_Datasets/conversation_datasets_GPT.csv\", header=True, inferSchema=True)\n",
    "base_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|Conversation_ID|Attacker_Helper                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |Victim                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |Conversation_Type|\n",
      "+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|GT1sURbxgG_0   |[['hi', 'thi', 'is', 'john', 'from', 'the', 'ir', 'you', 'owe', 'us', 'xxxxx', 'in', 'back', 'tax']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |[['im', 'sorri', 'i', 'dont', 'believ', 'you', 'can', 'you', 'provid', 'me', 'with', 'your', 'badg', 'number']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |1                |\n",
      "|GT1sURbxgG_1   |[['hi', 'thi', 'is', 'john', 'from', 'the', 'ir', 'you', 'owe', 'us', 'xxxxx', 'in', 'back', 'tax', 'ye', 'of', 'cours', 'it', 'xxxx']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |[['im', 'sorri', 'i', 'dont', 'believ', 'you', 'can', 'you', 'provid', 'me', 'with', 'your', 'badg', 'number', 'im', 'still', 'not', 'sure', 'can', 'i', 'call', 'you', 'back', 'to', 'verifi', 'thi', 'inform']]                                                                                                                                                                                                                                                                                                                                                                                                                 |1                |\n",
      "|GT1sURbxgG_2   |[['hi', 'thi', 'is', 'john', 'from', 'the', 'ir', 'you', 'owe', 'us', 'xxxxx', 'in', 'back', 'tax', 'ye', 'of', 'cours', 'it', 'xxxx', 'no', 'you', 'can', 'not', 'we', 'need', 'payment', 'immedi', 'or', 'we', 'will', 'send', 'the', 'polic', 'to', 'your', 'hous']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |[['im', 'sorri', 'i', 'dont', 'believ', 'you', 'can', 'you', 'provid', 'me', 'with', 'your', 'badg', 'number', 'im', 'still', 'not', 'sure', 'can', 'i', 'call', 'you', 'back', 'to', 'verifi', 'thi', 'inform', 'i', 'dont', 'think', 'that', 'legal', 'ill', 'be', 'contact', 'the', 'ir', 'directli', 'to', 'confirm', 'thi']]                                                                                                                                                                                                                                                                                                 |1                |\n",
      "|TwaGOeC96w_0   |[['hello', 'thi', 'is', 'xyz', 'bank', 'call', 'may', 'i', 'speak', 'with', 'victim', 'name', 'pleas']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |[['thi', 'is', 'victim', 'name', 'how', 'can', 'i', 'help', 'you']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |0                |\n",
      "|TwaGOeC96w_1   |[['hello', 'thi', 'is', 'xyz', 'bank', 'call', 'may', 'i', 'speak', 'with', 'victim', 'name', 'pleas', 'good', 'morn', 'victim', 'name', 'we', 'just', 'notic', 'some', 'unusu', 'activ', 'on', 'your', 'account', 'and', 'want', 'to', 'verifi', 'a', 'few', 'thing', 'can', 'you', 'confirm', 'your', 'account', 'number', 'for', 'me']]                                                                                                                                                                                                                                                                                                                                                                                                 |[['thi', 'is', 'victim', 'name', 'how', 'can', 'i', 'help', 'you', 'im', 'sorri', 'i', 'dont', 'feel', 'comfort', 'give', 'out', 'my', 'account', 'number', 'on', 'the', 'phone', 'is', 'there', 'anoth', 'way', 'we', 'can', 'verifi', 'my', 'inform']]                                                                                                                                                                                                                                                                                                                                                                          |0                |\n",
      "|TwaGOeC96w_2   |[['hello', 'thi', 'is', 'xyz', 'bank', 'call', 'may', 'i', 'speak', 'with', 'victim', 'name', 'pleas', 'good', 'morn', 'victim', 'name', 'we', 'just', 'notic', 'some', 'unusu', 'activ', 'on', 'your', 'account', 'and', 'want', 'to', 'verifi', 'a', 'few', 'thing', 'can', 'you', 'confirm', 'your', 'account', 'number', 'for', 'me', 'absolut', 'we', 'complet', 'understand', 'your', 'concern', 'can', 'you', 'pleas', 'provid', 'your', 'date', 'of', 'birth', 'and', 'social', 'secur', 'number', 'for', 'verif', 'purpos']]                                                                                                                                                                                                      |[['thi', 'is', 'victim', 'name', 'how', 'can', 'i', 'help', 'you', 'im', 'sorri', 'i', 'dont', 'feel', 'comfort', 'give', 'out', 'my', 'account', 'number', 'on', 'the', 'phone', 'is', 'there', 'anoth', 'way', 'we', 'can', 'verifi', 'my', 'inform', 'im', 'still', 'hesit', 'to', 'provid', 'that', 'inform', 'over', 'the', 'phone', 'can', 'i', 'come', 'into', 'the', 'bank', 'and', 'verifi', 'my', 'inform', 'in', 'person']]                                                                                                                                                                                            |1                |\n",
      "|TwaGOeC96w_3   |[['hello', 'thi', 'is', 'xyz', 'bank', 'call', 'may', 'i', 'speak', 'with', 'victim', 'name', 'pleas', 'good', 'morn', 'victim', 'name', 'we', 'just', 'notic', 'some', 'unusu', 'activ', 'on', 'your', 'account', 'and', 'want', 'to', 'verifi', 'a', 'few', 'thing', 'can', 'you', 'confirm', 'your', 'account', 'number', 'for', 'me', 'absolut', 'we', 'complet', 'understand', 'your', 'concern', 'can', 'you', 'pleas', 'provid', 'your', 'date', 'of', 'birth', 'and', 'social', 'secur', 'number', 'for', 'verif', 'purpos', 'of', 'cours', 'that', 'a', 'great', 'idea', 'our', 'branch', 'hour', 'are', 'xamxpm', 'monday', 'through', 'friday', 'is', 'there', 'a', 'day', 'and', 'time', 'that', 'work', 'best', 'for', 'you']]|[['thi', 'is', 'victim', 'name', 'how', 'can', 'i', 'help', 'you', 'im', 'sorri', 'i', 'dont', 'feel', 'comfort', 'give', 'out', 'my', 'account', 'number', 'on', 'the', 'phone', 'is', 'there', 'anoth', 'way', 'we', 'can', 'verifi', 'my', 'inform', 'im', 'still', 'hesit', 'to', 'provid', 'that', 'inform', 'over', 'the', 'phone', 'can', 'i', 'come', 'into', 'the', 'bank', 'and', 'verifi', 'my', 'inform', 'in', 'person', 'ye', 'i', 'can', 'come', 'in', 'on', 'thursday', 'at', 'around', 'xpm', 'thank', 'you', 'for', 'understand']]                                                                              |0                |\n",
      "|V73ZDCviQL_0   |[['hello', 'sir', 'thi', 'is', 'a', 'call', 'from', 'the', 'ir', 'we', 'have', 'found', 'discrep', 'in', 'your', 'tax', 'file', 'and', 'need', 'to', 'verifi', 'some', 'inform']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |[['ive', 'never', 'had', 'ani', 'issu', 'with', 'my', 'tax', 'befor', 'can', 'you', 'provid', 'me', 'with', 'more', 'specif', 'inform']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |0                |\n",
      "|V73ZDCviQL_1   |[['hello', 'sir', 'thi', 'is', 'a', 'call', 'from', 'the', 'ir', 'we', 'have', 'found', 'discrep', 'in', 'your', 'tax', 'file', 'and', 'need', 'to', 'verifi', 'some', 'inform', 'ye', 'sir', 'we', 'need', 'your', 'social', 'secur', 'number', 'and', 'bank', 'account', 'detail', 'to', 'verifi', 'the', 'inform']]                                                                                                                                                                                                                                                                                                                                                                                                                     |[['ive', 'never', 'had', 'ani', 'issu', 'with', 'my', 'tax', 'befor', 'can', 'you', 'provid', 'me', 'with', 'more', 'specif', 'inform', 'im', 'sorri', 'but', 'i', 'dont', 'feel', 'comfort', 'share', 'that', 'inform', 'over', 'the', 'phone', 'can', 'you', 'send', 'me', 'an', 'email', 'or', 'mail', 'me', 'a', 'letter', 'instead']]                                                                                                                                                                                                                                                                                        |0                |\n",
      "|V73ZDCviQL_2   |[['hello', 'sir', 'thi', 'is', 'a', 'call', 'from', 'the', 'ir', 'we', 'have', 'found', 'discrep', 'in', 'your', 'tax', 'file', 'and', 'need', 'to', 'verifi', 'some', 'inform', 'ye', 'sir', 'we', 'need', 'your', 'social', 'secur', 'number', 'and', 'bank', 'account', 'detail', 'to', 'verifi', 'the', 'inform', 'there', 'no', 'need', 'to', 'worri', 'sir', 'we', 'are', 'a', 'legitim', 'organ', 'and', 'need', 'thi', 'inform', 'to', 'resolv', 'the', 'issu', 'quickli']]                                                                                                                                                                                                                                                        |[['ive', 'never', 'had', 'ani', 'issu', 'with', 'my', 'tax', 'befor', 'can', 'you', 'provid', 'me', 'with', 'more', 'specif', 'inform', 'im', 'sorri', 'but', 'i', 'dont', 'feel', 'comfort', 'share', 'that', 'inform', 'over', 'the', 'phone', 'can', 'you', 'send', 'me', 'an', 'email', 'or', 'mail', 'me', 'a', 'letter', 'instead', 'i', 'appreci', 'your', 'concern', 'but', 'i', 'still', 'can', 'not', 'provid', 'that', 'inform', 'over', 'the', 'phone', 'can', 'you', 'pleas', 'provid', 'me', 'with', 'a', 'refer', 'number', 'for', 'thi', 'issu', 'so', 'i', 'can', 'verifi', 'it', 'with', 'the', 'ir', 'myself']]|1                |\n",
      "+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df = spark.read.csv(\"../../Data/Preprocessed_Datasets/DATASET_FINAL_PREPROCESSED.csv\", header=True, inferSchema=True)\n",
    "preprocessed_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Conversation Columns into actual Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Conversation_ID: string (nullable = true)\n",
      " |-- Attacker_Helper: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- Victim: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- Conversation_Type: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.functions import udf\n",
    "import ast\n",
    "\n",
    "# UDF to convert string representation of list to actual list\n",
    "def str_to_array_of_arrays(s):\n",
    "    # Convert the string to a list and then wrap it inside another list\n",
    "    return [ast.literal_eval(s)][0]\n",
    "\n",
    "str_to_array_of_arrays_udf = udf(str_to_array_of_arrays, ArrayType(ArrayType(StringType())))\n",
    "\n",
    "df = preprocessed_df.withColumn(\"Attacker_Helper\", str_to_array_of_arrays_udf(preprocessed_df[\"Attacker_Helper\"])).withColumn(\"Victim\", str_to_array_of_arrays_udf(preprocessed_df[\"Victim\"]))\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a feed forward neural network using keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data to be used as input in the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'thi', 'is', 'john', 'from', 'the', 'ir', 'you', 'owe', 'us', 'xxxxx', 'in', 'back', 'tax']\n",
      "['hi', 'thi', 'is', 'john', 'from', 'the', 'ir', 'you', 'owe', 'us', 'xxxxx', 'in', 'back', 'tax', 'ye', 'of', 'cours', 'it', 'xxxx']\n",
      "['im', 'sorri', 'i', 'dont', 'believ', 'you', 'can', 'you', 'provid', 'me', 'with', 'your', 'badg', 'number']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "dataframe = df.toPandas()\n",
    "\n",
    "attacker_texts = dataframe['Attacker_Helper'].values\n",
    "victim_texts = dataframe['Victim'].values\n",
    "\n",
    "labels = dataframe['Conversation_Type'].values\n",
    "\n",
    "# Ensure attacker_texts is a flat list of strings\n",
    "flat_attacker_texts = [item for sublist in attacker_texts for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "\n",
    "# Ensure victim_texts is a flat list of strings\n",
    "flat_victim_texts = [item for sublist in victim_texts for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "\n",
    "print(flat_attacker_texts[0])\n",
    "print(flat_victim_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[339, 8, 9, 50, 30, 3, 62, 2, 170, 121, 303, 35, 94, 74]\n",
      "[27, 81, 5, 55, 268, 2, 7, 2, 16, 23, 20, 1, 284, 21]\n",
      "Shape of Combined Data: (3588, 766)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "# Now, fit the tokenizer on the flattened text data\n",
    "tokenizer.fit_on_texts(flat_attacker_texts + flat_victim_texts)\n",
    "\n",
    "\n",
    "attacker_sequences = tokenizer.texts_to_sequences(flat_attacker_texts)\n",
    "victim_sequences = tokenizer.texts_to_sequences(flat_victim_texts)\n",
    "\n",
    "print(attacker_sequences[0])\n",
    "print(victim_sequences[0])\n",
    "\n",
    "# Find the maximum length from both columns for padding\n",
    "max_length_attacker = max([len(seq) for seq in attacker_sequences])\n",
    "max_length_victim = max([len(seq) for seq in victim_sequences])\n",
    "max_sequence_length = max(max_length_attacker, max_length_victim)  # Use the max length found for padding\n",
    "\n",
    "# Pad sequences to have the same length\n",
    "attacker_data = pad_sequences(attacker_sequences, maxlen=max_sequence_length)\n",
    "victim_data = pad_sequences(victim_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "\n",
    "\n",
    "combined_data = np.concatenate([attacker_data, victim_data], axis=1)  # Concatenate along the sequence length\n",
    "\n",
    "# Get the size of the vocabulary (adding 1 because Tokenizer is 1-indexed)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"Shape of Combined Data:\", combined_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder_path = '../Models/Tokenizers'\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    \n",
    "file_path = os.path.join(folder_path, 'tokenizer.json')\n",
    "\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(tokenizer_json) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (2870, 766)\n",
      "Training labels shape (2870,)\n",
      "Test data shape (718, 766)\n",
      "Test labels shape (718,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming combined_data is your feature data and labels are your target labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2)\n",
    "\n",
    "print(\"Training data shape\", X_train.shape)\n",
    "print(\"Training labels shape\", y_train.shape)\n",
    "\n",
    "print(\"Test data shape\", X_test.shape)\n",
    "print(\"Test labels shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPER PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_12292\\832161708.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperModel\n"
     ]
    }
   ],
   "source": [
    "from kerastuner import HyperModel\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD, Nadam\n",
    "from src.CustomNNMetrics import F1Score\n",
    "\n",
    "\n",
    "class NNHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Embedding Layer\n",
    "        # Embedding Layer as the first layer\n",
    "        model.add(Embedding(input_dim=hp.Int('vocab_size', min_value=1000, max_value=10000, step=1000),  # Vocabulary size\n",
    "                            output_dim=hp.Int('embedding_output_dim', min_value=32, max_value=128, step=16),  # Output dimension of the embeddings\n",
    "                            input_length=766)) \n",
    "        \n",
    "        model.add(Flatten())\n",
    "        \n",
    "        # Layer 1\n",
    "        model.add(Dense(units=hp.Int('units_first_layer', min_value=16, max_value=128, step=16), \n",
    "                        activation='relu', \n",
    "                        kernel_regularizer=l1_l2(l1=hp.Float('l1_first_layer', min_value=1e-7, max_value=1e-2, sampling='LOG'),\n",
    "                                                 l2=hp.Float('l2_first_layer', min_value=1e-7, max_value=1e-2, sampling='LOG'))))\n",
    "        \n",
    "        model.add(Dropout(rate=hp.Float('dropout_first_layer', min_value=0.0, max_value=0.7, step=0.05)))\n",
    "        \n",
    "        # Layer 2\n",
    "        model.add(Dense(units=hp.Int('units_second_layer', min_value=16, max_value=128, step=16), \n",
    "                        activation='relu', \n",
    "                        kernel_regularizer=l1_l2(l1=hp.Float('l1_second_layer', min_value=1e-7, max_value=1e-2, sampling='LOG'),\n",
    "                                                 l2=hp.Float('l2_second_layer', min_value=1e-7, max_value=1e-2, sampling='LOG'))))\n",
    "\n",
    "        model.add(Dropout(rate=hp.Float('dropout_second_layer', min_value=0.0, max_value=0.7, step=0.05)))\n",
    "        \n",
    "        # Layer 3\n",
    "        model.add(Dense(units=hp.Int('units_third_layer', min_value=16, max_value=128, step=16), \n",
    "                        activation='relu', \n",
    "                        kernel_regularizer=l1_l2(l1=hp.Float('l1_third_layer', min_value=1e-7, max_value=1e-2, sampling='LOG'),\n",
    "                                                 l2=hp.Float('l2_third_layer', min_value=1e-7, max_value=1e-2, sampling='LOG'))))\n",
    "        \n",
    "        model.add(Dropout(rate=hp.Float('dropout_third_layer', min_value=0.0, max_value=0.7, step=0.05)))\n",
    "        \n",
    "        # Output Layer\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        optimizer_choice = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop', 'nadam'])\n",
    "        \n",
    "        if optimizer_choice == 'adam':\n",
    "            optimizer = Adam(\n",
    "                learning_rate=hp.Float('adam_learning_rate', 1e-5, 1e-2, sampling='LOG'),\n",
    "                beta_1=hp.Float('adam_beta_1', 0.85, 0.95, sampling='LOG'),\n",
    "                beta_2=hp.Float('adam_beta_2', 0.99, 0.999, sampling='LOG')\n",
    "            )\n",
    "        elif optimizer_choice == 'sgd':\n",
    "            optimizer = SGD(\n",
    "                learning_rate=hp.Float('sgd_learning_rate', 1e-5, 1e-2, sampling='LOG'),\n",
    "                momentum=hp.Float('sgd_momentum', 0.1, 0.9, sampling='LOG')\n",
    "            )\n",
    "        elif optimizer_choice == 'rmsprop':\n",
    "            optimizer = RMSprop(\n",
    "                learning_rate=hp.Float('rmsprop_learning_rate', 1e-5, 1e-2, sampling='LOG'),\n",
    "                rho=hp.Float('rmsprop_rho', 0.85, 0.95, sampling='LOG')\n",
    "            )\n",
    "        elif optimizer_choice == 'nadam':\n",
    "            optimizer = Nadam(\n",
    "                learning_rate=hp.Float('nadam_learning_rate', 1e-5, 1e-2, sampling='LOG'),\n",
    "                beta_1=hp.Float('nadam_beta_1', 0.85, 0.95, sampling='LOG'),\n",
    "                beta_2=hp.Float('nadam_beta_2', 0.99, 0.999, sampling='LOG')\n",
    "            )\n",
    "            \n",
    "        model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), F1Score()])\n",
    "        \n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuner Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ../../Logs/Keras_Tuning\\../../Logs/Keras_Tuning/Neural_Network_Tuning_EMBEDDING\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner import Objective\n",
    "\n",
    "hyper_model = NNHyperModel()\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hyper_model,\n",
    "    objective=Objective(\"val_loss\", direction=\"min\"),\n",
    "    max_epochs=200,\n",
    "    directory='../../Logs/Keras_Tuning',\n",
    "    project_name='../../Logs/Keras_Tuning/Neural_Network_Tuning_EMBEDDING'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for the Best Hyperparameters & Retrieving Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 201 Complete [00h 01m 06s]\n",
      "val_loss: 0.4803275465965271\n",
      "\n",
      "Best val_loss So Far: 0.3113371431827545\n",
      "Total elapsed time: 02h 16m 33s\n",
      "\n",
      "Search: Running Trial #202\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "4000              |4000              |vocab_size\n",
      "112               |64                |embedding_output_dim\n",
      "48                |32                |units_first_layer\n",
      "4.0708e-07        |1.7424e-07        |l1_first_layer\n",
      "1.6901e-05        |1.9465e-05        |l2_first_layer\n",
      "0.15              |0.25              |dropout_first_layer\n",
      "48                |112               |units_second_layer\n",
      "5.6587e-07        |0.00037539        |l1_second_layer\n",
      "4.8931e-05        |0.00051632        |l2_second_layer\n",
      "0.05              |0.6               |dropout_second_layer\n",
      "16                |48                |units_third_layer\n",
      "5.3134e-05        |8.235e-06         |l1_third_layer\n",
      "1.2334e-07        |2.578e-06         |l2_third_layer\n",
      "0.55              |0.05              |dropout_third_layer\n",
      "rmsprop           |rmsprop           |optimizer\n",
      "2.846e-05         |0.00054755        |adam_learning_rate\n",
      "0.87774           |0.86853           |adam_beta_1\n",
      "0.99237           |0.99182           |adam_beta_2\n",
      "5.1916e-05        |0.0004097         |rmsprop_learning_rate\n",
      "0.90749           |0.94378           |rmsprop_rho\n",
      "0.00052007        |0.00036914        |nadam_learning_rate\n",
      "0.9037            |0.92211           |nadam_beta_1\n",
      "0.99214           |0.99714           |nadam_beta_2\n",
      "2.0192e-05        |0.0098561         |sgd_learning_rate\n",
      "0.49379           |0.19869           |sgd_momentum\n",
      "200               |67                |tuner/epochs\n",
      "67                |23                |tuner/initial_epoch\n",
      "1                 |2                 |tuner/bracket\n",
      "1                 |1                 |tuner/round\n",
      "0194              |0174              |tuner/trial_id\n",
      "\n",
      "Epoch 68/200\n",
      "72/72 [==============================] - 5s 53ms/step - loss: 0.2529 - accuracy: 0.9098 - precision: 0.9254 - recall: 0.9488 - f1_score: 0.9369 - val_loss: 0.4250 - val_accuracy: 0.8397 - val_precision: 0.8404 - val_recall: 0.9499 - val_f1_score: 0.8918\n",
      "Epoch 69/200\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.2518 - accuracy: 0.9085 - precision: 0.9187 - recall: 0.9550 - f1_score: 0.9365 - val_loss: 0.3832 - val_accuracy: 0.8537 - val_precision: 0.8637 - val_recall: 0.9373 - val_f1_score: 0.8990\n",
      "Epoch 70/200\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.2321 - accuracy: 0.9251 - precision: 0.9341 - recall: 0.9618 - f1_score: 0.9477 - val_loss: 0.3809 - val_accuracy: 0.8519 - val_precision: 0.8651 - val_recall: 0.9323 - val_f1_score: 0.8975\n",
      "Epoch 71/200\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2259 - accuracy: 0.9247 - precision: 0.9361 - recall: 0.9587 - f1_score: 0.9473 - val_loss: 0.4489 - val_accuracy: 0.8362 - val_precision: 0.8322 - val_recall: 0.9574 - val_f1_score: 0.8904\n",
      "Epoch 72/200\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2149 - accuracy: 0.9268 - precision: 0.9374 - recall: 0.9605 - f1_score: 0.9488 - val_loss: 0.3910 - val_accuracy: 0.8519 - val_precision: 0.8634 - val_recall: 0.9348 - val_f1_score: 0.8977\n",
      "Epoch 73/200\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.1916 - accuracy: 0.9416 - precision: 0.9542 - recall: 0.9636 - f1_score: 0.9589 - val_loss: 0.4521 - val_accuracy: 0.8397 - val_precision: 0.8359 - val_recall: 0.9574 - val_f1_score: 0.8925\n",
      "Epoch 74/200\n",
      "72/72 [==============================] - 3s 49ms/step - loss: 0.1878 - accuracy: 0.9412 - precision: 0.9498 - recall: 0.9679 - f1_score: 0.9588 - val_loss: 0.4817 - val_accuracy: 0.8397 - val_precision: 0.8344 - val_recall: 0.9599 - val_f1_score: 0.8928\n",
      "Epoch 75/200\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.1821 - accuracy: 0.9438 - precision: 0.9489 - recall: 0.9729 - f1_score: 0.9607 - val_loss: 0.4015 - val_accuracy: 0.8589 - val_precision: 0.8750 - val_recall: 0.9298 - val_f1_score: 0.9016\n",
      "Epoch 76/200\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1756 - accuracy: 0.9429 - precision: 0.9510 - recall: 0.9692 - f1_score: 0.9600 - val_loss: 0.4056 - val_accuracy: 0.8571 - val_precision: 0.8712 - val_recall: 0.9323 - val_f1_score: 0.9007\n",
      "Epoch 77/200\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1702 - accuracy: 0.9503 - precision: 0.9575 - recall: 0.9729 - f1_score: 0.9651 - val_loss: 0.4296 - val_accuracy: 0.8484 - val_precision: 0.8545 - val_recall: 0.9424 - val_f1_score: 0.8963\n",
      "Epoch 78/200\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.1585 - accuracy: 0.9547 - precision: 0.9662 - recall: 0.9698 - f1_score: 0.9680 - val_loss: 0.4312 - val_accuracy: 0.8519 - val_precision: 0.8634 - val_recall: 0.9348 - val_f1_score: 0.8977\n",
      "Epoch 79/200\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1561 - accuracy: 0.9556 - precision: 0.9685 - recall: 0.9685 - f1_score: 0.9685 - val_loss: 0.4013 - val_accuracy: 0.8676 - val_precision: 0.9130 - val_recall: 0.8947 - val_f1_score: 0.9038\n",
      "Epoch 80/200\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.1431 - accuracy: 0.9621 - precision: 0.9752 - recall: 0.9710 - f1_score: 0.9731 - val_loss: 0.4645 - val_accuracy: 0.8502 - val_precision: 0.8549 - val_recall: 0.9449 - val_f1_score: 0.8976\n",
      "Epoch 81/200\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.1459 - accuracy: 0.9591 - precision: 0.9733 - recall: 0.9685 - f1_score: 0.9709 - val_loss: 0.4563 - val_accuracy: 0.8537 - val_precision: 0.8621 - val_recall: 0.9398 - val_f1_score: 0.8993\n",
      "Epoch 82/200\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.1282 - accuracy: 0.9673 - precision: 0.9789 - recall: 0.9747 - f1_score: 0.9768 - val_loss: 0.4635 - val_accuracy: 0.8554 - val_precision: 0.8641 - val_recall: 0.9398 - val_f1_score: 0.9004\n",
      "Epoch 83/200\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.1243 - accuracy: 0.9678 - precision: 0.9778 - recall: 0.9766 - f1_score: 0.9772 - val_loss: 0.4616 - val_accuracy: 0.8606 - val_precision: 0.8718 - val_recall: 0.9373 - val_f1_score: 0.9034\n",
      "Epoch 84/200\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.1198 - accuracy: 0.9708 - precision: 0.9802 - recall: 0.9784 - f1_score: 0.9793 - val_loss: 0.5153 - val_accuracy: 0.8484 - val_precision: 0.8498 - val_recall: 0.9499 - val_f1_score: 0.8970\n",
      "Epoch 85/200\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1130 - accuracy: 0.9691 - precision: 0.9808 - recall: 0.9753 - f1_score: 0.9780 - val_loss: 0.4890 - val_accuracy: 0.8589 - val_precision: 0.8698 - val_recall: 0.9373 - val_f1_score: 0.9023\n",
      "Epoch 86/200\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.1109 - accuracy: 0.9717 - precision: 0.9832 - recall: 0.9766 - f1_score: 0.9799 - val_loss: 0.4770 - val_accuracy: 0.8589 - val_precision: 0.8732 - val_recall: 0.9323 - val_f1_score: 0.9018\n",
      "Epoch 87/200\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1124 - accuracy: 0.9682 - precision: 0.9790 - recall: 0.9759 - f1_score: 0.9774 - val_loss: 0.5596 - val_accuracy: 0.8484 - val_precision: 0.8498 - val_recall: 0.9499 - val_f1_score: 0.8970\n",
      "Epoch 88/200\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1089 - accuracy: 0.9699 - precision: 0.9784 - recall: 0.9790 - f1_score: 0.9787 - val_loss: 0.5216 - val_accuracy: 0.8589 - val_precision: 0.8664 - val_recall: 0.9424 - val_f1_score: 0.9028\n",
      "Epoch 89/200\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.1015 - accuracy: 0.9708 - precision: 0.9796 - recall: 0.9790 - f1_score: 0.9793 - val_loss: 0.5505 - val_accuracy: 0.8537 - val_precision: 0.8588 - val_recall: 0.9449 - val_f1_score: 0.8998\n",
      "Epoch 90/200\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1059 - accuracy: 0.9704 - precision: 0.9820 - recall: 0.9759 - f1_score: 0.9790 - val_loss: 0.5114 - val_accuracy: 0.8606 - val_precision: 0.8789 - val_recall: 0.9273 - val_f1_score: 0.9024\n",
      "Epoch 91/200\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.0971 - accuracy: 0.9739 - precision: 0.9827 - recall: 0.9803 - f1_score: 0.9815 - val_loss: 0.6023 - val_accuracy: 0.8484 - val_precision: 0.8514 - val_recall: 0.9474 - val_f1_score: 0.8968\n",
      "Epoch 92/200\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.0867 - accuracy: 0.9800 - precision: 0.9864 - recall: 0.9852 - f1_score: 0.9858 - val_loss: 0.5282 - val_accuracy: 0.8589 - val_precision: 0.8768 - val_recall: 0.9273 - val_f1_score: 0.9013\n",
      "Epoch 93/200\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.0899 - accuracy: 0.9800 - precision: 0.9876 - recall: 0.9840 - f1_score: 0.9858 - val_loss: 0.6129 - val_accuracy: 0.8502 - val_precision: 0.8517 - val_recall: 0.9499 - val_f1_score: 0.8981\n",
      "Epoch 94/200\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.0892 - accuracy: 0.9774 - precision: 0.9846 - recall: 0.9833 - f1_score: 0.9840 - val_loss: 0.5779 - val_accuracy: 0.8589 - val_precision: 0.8732 - val_recall: 0.9323 - val_f1_score: 0.9018\n",
      "Epoch 95/200\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.0855 - accuracy: 0.9782 - precision: 0.9876 - recall: 0.9815 - f1_score: 0.9845 - val_loss: 0.5721 - val_accuracy: 0.8589 - val_precision: 0.8732 - val_recall: 0.9323 - val_f1_score: 0.9018\n",
      "Epoch 96/200\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.0816 - accuracy: 0.9795 - precision: 0.9888 - recall: 0.9821 - f1_score: 0.9855 - val_loss: 0.6573 - val_accuracy: 0.8537 - val_precision: 0.8539 - val_recall: 0.9524 - val_f1_score: 0.9005\n",
      "Epoch 97/200\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.0763 - accuracy: 0.9830 - precision: 0.9895 - recall: 0.9864 - f1_score: 0.9880 - val_loss: 0.5527 - val_accuracy: 0.8554 - val_precision: 0.8835 - val_recall: 0.9123 - val_f1_score: 0.8977\n",
      "Epoch 98/200\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.0796 - accuracy: 0.9800 - precision: 0.9894 - recall: 0.9821 - f1_score: 0.9858 - val_loss: 0.5839 - val_accuracy: 0.8554 - val_precision: 0.8726 - val_recall: 0.9273 - val_f1_score: 0.8991\n",
      "Epoch 99/200\n",
      "72/72 [==============================] - 3s 49ms/step - loss: 0.0769 - accuracy: 0.9813 - precision: 0.9888 - recall: 0.9846 - f1_score: 0.9867 - val_loss: 0.6050 - val_accuracy: 0.8571 - val_precision: 0.8729 - val_recall: 0.9298 - val_f1_score: 0.9005\n",
      "Epoch 100/200\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.0706 - accuracy: 0.9834 - precision: 0.9925 - recall: 0.9840 - f1_score: 0.9882 - val_loss: 0.6038 - val_accuracy: 0.8606 - val_precision: 0.8807 - val_recall: 0.9248 - val_f1_score: 0.9022\n",
      "Epoch 101/200\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.0751 - accuracy: 0.9826 - precision: 0.9901 - recall: 0.9852 - f1_score: 0.9876 - val_loss: 0.7554 - val_accuracy: 0.8554 - val_precision: 0.8435 - val_recall: 0.9724 - val_f1_score: 0.9034\n",
      "Epoch 102/200\n",
      " 7/72 [=>............................] - ETA: 2s - loss: 0.0410 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 233\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 238\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    241\u001b[0m     ):\n\u001b[0;32m    242\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    254\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\johns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=200,\n",
    "             validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing the tuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial ID: 0188\n",
      "Best Trial Score: 0.3113371431827545\n",
      "Best Hyperparameters:\n",
      "\tvocab_size: 4000\n",
      "\tembedding_output_dim: 64\n",
      "\tunits_first_layer: 32\n",
      "\tl1_first_layer: 1.7423896638458018e-07\n",
      "\tl2_first_layer: 1.946493037309278e-05\n",
      "\tdropout_first_layer: 0.25\n",
      "\tunits_second_layer: 112\n",
      "\tl1_second_layer: 0.0003753897006106875\n",
      "\tl2_second_layer: 0.000516323481041702\n",
      "\tdropout_second_layer: 0.6000000000000001\n",
      "\tunits_third_layer: 48\n",
      "\tl1_third_layer: 8.234990826115495e-06\n",
      "\tl2_third_layer: 2.577977945979165e-06\n",
      "\tdropout_third_layer: 0.05\n",
      "\toptimizer: rmsprop\n",
      "\tadam_learning_rate: 0.0005475517926888837\n",
      "\tadam_beta_1: 0.8685251271554257\n",
      "\tadam_beta_2: 0.9918240365811867\n",
      "\trmsprop_learning_rate: 0.00040970392330878926\n",
      "\trmsprop_rho: 0.9437790600037682\n",
      "\tnadam_learning_rate: 0.0003691391455505471\n",
      "\tnadam_beta_1: 0.9221111842170197\n",
      "\tnadam_beta_2: 0.9971394872235539\n",
      "\tsgd_learning_rate: 0.009856125192373095\n",
      "\tsgd_momentum: 0.1986927371253983\n",
      "\ttuner/epochs: 67\n",
      "\ttuner/initial_epoch: 23\n",
      "\ttuner/bracket: 2\n",
      "\ttuner/round: 1\n",
      "\ttuner/trial_id: 0174\n"
     ]
    }
   ],
   "source": [
    "# Get the best trial\n",
    "best_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "\n",
    "# Print the best trial's details\n",
    "print(f\"Best Trial ID: {best_trial.trial_id}\")\n",
    "print(f\"Best Trial Score: {best_trial.score}\")\n",
    "\n",
    "best_hyperparameters = best_trial.hyperparameters.values\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "for param, value in best_hyperparameters.items():\n",
    "    print(f\"\\t{param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 6ms/step - loss: 0.2839 - accuracy: 0.9220 - precision: 0.9491 - recall: 0.9376 - f1_score: 0.9433\n",
      "test_accuracy --> 0.9220055937767029\n",
      "test_loss --> 0.28385913372039795\n",
      "test_precision --> 0.9490835070610046\n",
      "test_recall --> 0.9376257658004761\n",
      "test_f1score --> 0.9433197975158691\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_f1score = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"test_accuracy --> {test_accuracy}\")\n",
    "print(f\"test_loss --> {test_loss}\")\n",
    "print(f\"test_precision --> {test_precision}\")\n",
    "print(f\"test_recall --> {test_recall}\")\n",
    "print(f\"test_f1score --> {test_f1score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"../Models/Trained_Models/NeuralNetwork_EMBEDDING/NeuralNetwork_EMBEDDING.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
