{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PreprocessDataset import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml import PipelineModel\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from scipy.sparse import hstack\n",
    "import pandas\n",
    "import socket\n",
    "import logging\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"G:\\Dissertation_Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prediction_model(model_id):\n",
    "    models = {\n",
    "        \"LogisticRegression_TFIDF\": \"G:\\\\Dissertation_Project\\\\src\\\\Models\\\\Trained_Models\\\\LogisticRegression\\\\bestModel\",\n",
    "        \"RandomForest_TFIDF\": \"G:\\\\Dissertation_Project\\\\src\\\\Models\\\\Trained_Models\\\\RandomForest\\\\bestModel\",\n",
    "        \"GradientBoosted_TFIDF\": \"G:\\\\Dissertation_Project\\\\src\\\\Models\\\\Trained_Models\\\\GradientBoostedTrees\\\\bestModel\",\n",
    "        \"SupportVectorMachine_TFIDF\": \"G:\\\\Dissertation_Project\\\\src\\\\Models\\\\Trained_Models\\\\SupportVectorMachine\\\\bestModel\",\n",
    "        \"NeuralNetwork_TFIDF\": \"G:\\\\Dissertation_Project\\\\src\\Models\\\\Trained_Models\\\\NeuralNetwork_TFIDF\\\\NeuralNetwork_TFIDF.keras\",\n",
    "        \"LSTM_NeuralNetwork_TFIDF\": \"G:\\\\Dissertation_Project\\\\src\\\\Models\\\\Trained_Models\\\\LSTM_NeuralNetwork_TFIDF\\\\LSTM_NeuralNetwork_TFIDF.keras\",\n",
    "        \"NeuralNetwork_EMBEDDING\": \"G:\\\\Dissertation_Project\\\\src\\Models\\\\Trained_Models\\\\NeuralNetwork_EMBEDDING\\\\NN_TEST_TFIDF.keras\"\n",
    "    }\n",
    "\n",
    "    print(\"<--LOADING PREDICTION MODEL : {} , From location : {}-->\\n\".format(\n",
    "        model_id, models[model_id]))\n",
    "\n",
    "    if not isinstance(model_id, str):\n",
    "        raise TypeError(model_id + \" must be of type str.\")\n",
    "\n",
    "    if not model_id in models.keys():\n",
    "        raise ValueError(\"model_id \" + model_id + \" does not exist.\")\n",
    "\n",
    "    try:\n",
    "        match (model_id):\n",
    "            case \"LogisticRegression_TFIDF\":\n",
    "                model = LogisticRegressionModel.load(models[model_id])\n",
    "                return model\n",
    "\n",
    "            case \"RandomForest_TFIDF\":\n",
    "                model = RandomForestClassificationModel.load(models[model_id])\n",
    "                return model\n",
    "\n",
    "            case \"GradientBoosted_TFIDF\":\n",
    "                model = GBTClassificationModel.load(models[model_id])\n",
    "                return model\n",
    "\n",
    "            case \"SupportVectorMachine_TFIDF\":\n",
    "                model = LinearSVCModel.load(models[model_id])\n",
    "                return model\n",
    "\n",
    "            case \"NeuralNetwork_TFIDF\":\n",
    "                from src.CustomNNMetrics import F1Score\n",
    "                model = load_model(models[model_id], custom_objects={\n",
    "                                   'F1Score': F1Score})\n",
    "                return model\n",
    "\n",
    "            case \"LSTM_NeuralNetwork_TFIDF\":\n",
    "                from src.CustomNNMetrics import F1Score\n",
    "                model = load_model(models[model_id], custom_objects={\n",
    "                                   'F1Score': F1Score})\n",
    "                return model\n",
    "\n",
    "            case \"NeuralNetwork_EMBEDDING\":\n",
    "                from src.CustomNNMetrics import F1Score\n",
    "                model = load_model(models[model_id], custom_objects={\n",
    "                                   'F1Score': F1Score})\n",
    "                return model\n",
    "\n",
    "            case _:\n",
    "                model = LogisticRegressionModel.load(\n",
    "                    models[\"LogisticRegression_TFIDF\"])\n",
    "                return model\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<--LOADING PREDICTION MODEL : NeuralNetwork_TFIDF , From location : G:\\Dissertation_Project\\src\\Models\\Trained_Models\\NeuralNetwork_TFIDF\\NeuralNetwork_TFIDF.keras-->\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Nadam', because it has 17 variables whereas the saved optimizer has 1 variables. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prediction_model = load_prediction_model(\"NeuralNetwork_TFIDF\")\n",
    "\n",
    "# Handle preprocessing for the neural network\n",
    "num_features = 200\n",
    "# Initialize HashingVectorizer to do the hashing trick\n",
    "hashing_vectorizer_ah = HashingVectorizer(\n",
    "    n_features=num_features, alternate_sign=False)\n",
    "hashing_vectorizer_v = HashingVectorizer(\n",
    "    n_features=num_features, alternate_sign=False)\n",
    "# Initialize TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(\n",
    "    use_idf=True, norm=None, smooth_idf=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['im', 'sorri', 'i', 'dont', 'believ', 'you', 'can', 'you', 'provid', 'me', 'with', 'your', 'badg', 'number']]\n",
      "[['hi', 'thi', 'is', 'john', 'from', 'the', 'ir', 'you', 'owe', 'us', 'xxxxx', 'in', 'back', 'tax']]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../Data/Preprocessed_Datasets/DATASET_FINAL_PREPROCESSED.csv')\n",
    "microphone_values = df['Victim'].values\n",
    "loopback_values = df['Attacker_Helper'].values\n",
    "labels = df['Conversation_Type'].values\n",
    "\n",
    "microphone_data = microphone_values[0]\n",
    "loopback_data = loopback_values[0]\n",
    "\n",
    "label = labels[0]\n",
    "\n",
    "print(microphone_data)\n",
    "print(loopback_data)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated_loop_data: [['hi', 'thi', 'is', 'john', 'from', 'the', 'ir', 'you', 'owe', 'us', 'xxxxx', 'in', 'back', 'tax']]\n",
      "\n",
      "Concatenated_mic_data: [['im', 'sorri', 'i', 'dont', 'believ', 'you', 'can', 'you', 'provid', 'me', 'with', 'your', 'badg', 'number']]\n",
      "\n",
      "Hashed_loop_data:   (0, 6)\t0.2672612419124244\n",
      "  (0, 42)\t0.2672612419124244\n",
      "  (0, 52)\t0.2672612419124244\n",
      "  (0, 72)\t0.2672612419124244\n",
      "  (0, 77)\t0.2672612419124244\n",
      "  (0, 89)\t0.2672612419124244\n",
      "  (0, 90)\t0.2672612419124244\n",
      "  (0, 96)\t0.2672612419124244\n",
      "  (0, 115)\t0.2672612419124244\n",
      "  (0, 122)\t0.2672612419124244\n",
      "  (0, 145)\t0.2672612419124244\n",
      "  (0, 158)\t0.2672612419124244\n",
      "  (0, 179)\t0.2672612419124244\n",
      "  (0, 188)\t0.2672612419124244\n",
      "\n",
      "Hashed_mic_data:   (0, 0)\t0.2581988897471611\n",
      "  (0, 19)\t0.2581988897471611\n",
      "  (0, 40)\t0.2581988897471611\n",
      "  (0, 55)\t0.2581988897471611\n",
      "  (0, 84)\t0.2581988897471611\n",
      "  (0, 136)\t0.2581988897471611\n",
      "  (0, 140)\t0.2581988897471611\n",
      "  (0, 156)\t0.2581988897471611\n",
      "  (0, 160)\t0.2581988897471611\n",
      "  (0, 180)\t0.2581988897471611\n",
      "  (0, 187)\t0.2581988897471611\n",
      "  (0, 188)\t0.5163977794943222\n",
      "\n",
      "TFIDF_loop_data:   (0, 188)\t0.2672612419124244\n",
      "  (0, 179)\t0.2672612419124244\n",
      "  (0, 158)\t0.2672612419124244\n",
      "  (0, 145)\t0.2672612419124244\n",
      "  (0, 122)\t0.2672612419124244\n",
      "  (0, 115)\t0.2672612419124244\n",
      "  (0, 96)\t0.2672612419124244\n",
      "  (0, 90)\t0.2672612419124244\n",
      "  (0, 89)\t0.2672612419124244\n",
      "  (0, 77)\t0.2672612419124244\n",
      "  (0, 72)\t0.2672612419124244\n",
      "  (0, 52)\t0.2672612419124244\n",
      "  (0, 42)\t0.2672612419124244\n",
      "  (0, 6)\t0.2672612419124244\n",
      "\n",
      "TFIDF_mic_data:   (0, 188)\t0.5163977794943222\n",
      "  (0, 187)\t0.2581988897471611\n",
      "  (0, 180)\t0.2581988897471611\n",
      "  (0, 160)\t0.2581988897471611\n",
      "  (0, 156)\t0.2581988897471611\n",
      "  (0, 140)\t0.2581988897471611\n",
      "  (0, 136)\t0.2581988897471611\n",
      "  (0, 84)\t0.2581988897471611\n",
      "  (0, 55)\t0.2581988897471611\n",
      "  (0, 40)\t0.2581988897471611\n",
      "  (0, 19)\t0.2581988897471611\n",
      "  (0, 0)\t0.2581988897471611\n",
      "\n",
      "Combined Features:   (0, 188)\t0.2672612419124244\n",
      "  (0, 179)\t0.2672612419124244\n",
      "  (0, 158)\t0.2672612419124244\n",
      "  (0, 145)\t0.2672612419124244\n",
      "  (0, 122)\t0.2672612419124244\n",
      "  (0, 115)\t0.2672612419124244\n",
      "  (0, 96)\t0.2672612419124244\n",
      "  (0, 90)\t0.2672612419124244\n",
      "  (0, 89)\t0.2672612419124244\n",
      "  (0, 77)\t0.2672612419124244\n",
      "  (0, 72)\t0.2672612419124244\n",
      "  (0, 52)\t0.2672612419124244\n",
      "  (0, 42)\t0.2672612419124244\n",
      "  (0, 6)\t0.2672612419124244\n",
      "  (0, 388)\t0.5163977794943222\n",
      "  (0, 387)\t0.2581988897471611\n",
      "  (0, 380)\t0.2581988897471611\n",
      "  (0, 360)\t0.2581988897471611\n",
      "  (0, 356)\t0.2581988897471611\n",
      "  (0, 340)\t0.2581988897471611\n",
      "  (0, 336)\t0.2581988897471611\n",
      "  (0, 284)\t0.2581988897471611\n",
      "  (0, 255)\t0.2581988897471611\n",
      "  (0, 240)\t0.2581988897471611\n",
      "  (0, 219)\t0.2581988897471611\n",
      "  (0, 200)\t0.2581988897471611\n",
      "\n",
      "Combined Features Dense Flattened: [0.         0.         0.         0.         0.         0.\n",
      " 0.26726124 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.26726124 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.26726124 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.26726124 0.         0.         0.         0.         0.26726124\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.26726124\n",
      " 0.26726124 0.         0.         0.         0.         0.\n",
      " 0.26726124 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.26726124 0.         0.         0.         0.\n",
      " 0.         0.         0.26726124 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.26726124 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.26726124 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.26726124\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.26726124 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.25819889 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.25819889 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.25819889 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.25819889 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.25819889 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.25819889 0.         0.         0.         0.25819889 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.25819889 0.         0.         0.\n",
      " 0.25819889 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.25819889 0.         0.         0.\n",
      " 0.         0.         0.         0.25819889 0.51639778 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "\n",
      "Combined Features Reshaped FINAL: [[0.         0.         0.         0.         0.         0.\n",
      "  0.26726124 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26726124 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.26726124 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26726124 0.         0.         0.         0.         0.26726124\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.26726124\n",
      "  0.26726124 0.         0.         0.         0.         0.\n",
      "  0.26726124 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26726124 0.         0.         0.         0.\n",
      "  0.         0.         0.26726124 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26726124 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.26726124 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.26726124\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.26726124 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25819889 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.25819889 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.25819889 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.25819889 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25819889 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.25819889 0.         0.         0.         0.25819889 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25819889 0.         0.         0.\n",
      "  0.25819889 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25819889 0.         0.         0.\n",
      "  0.         0.         0.         0.25819889 0.51639778 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "\n",
      "Combined Feature Reshaped FINAL Shape: (1, 400)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 224ms/step\n",
      "Predictions [[0.18852358]]\n",
      "Scam detected with probability: 0.8114764243364334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_for_logs = {\n",
    "    \"attacker_helper\": loopback_data,\n",
    "    \"victim\": microphone_data\n",
    "}\n",
    "# Concatenate texts\n",
    "concatenated_microphone_data = ''.join(microphone_data)\n",
    "concatenated_loopback_data = ''.join(loopback_data)\n",
    "\n",
    "print(\"Concatenated_loop_data: {}\\n\".format(concatenated_loopback_data))\n",
    "print(\"Concatenated_mic_data: {}\\n\".format(concatenated_microphone_data))\n",
    "\n",
    "# Implementing the hashing trick\n",
    "V_hashed_features = hashing_vectorizer_v.fit_transform(\n",
    "    [concatenated_microphone_data])\n",
    "AH_hashed_features = hashing_vectorizer_ah.fit_transform(\n",
    "    [concatenated_loopback_data])\n",
    "\n",
    "print(\"Hashed_loop_data: {}\\n\".format(AH_hashed_features))\n",
    "print(\"Hashed_mic_data: {}\\n\".format(V_hashed_features))\n",
    "\n",
    "# Apply IDF scaling\n",
    "AH_tfidf_scaled = tfidf_transformer.fit_transform(\n",
    "    AH_hashed_features)\n",
    "V_tfidf_scaled = tfidf_transformer.fit_transform(\n",
    "    V_hashed_features)\n",
    "\n",
    "print(\"TFIDF_loop_data: {}\\n\".format(AH_tfidf_scaled))\n",
    "print(\"TFIDF_mic_data: {}\\n\".format(V_tfidf_scaled))\n",
    "\n",
    "# Combining features\n",
    "combined_features = hstack(\n",
    "    [AH_tfidf_scaled, V_tfidf_scaled])\n",
    "\n",
    "\n",
    "# Convert to dense array and flatten\n",
    "combined_features_dense = combined_features.toarray().flatten()\n",
    "\n",
    "print(\"Combined Features: {}\\n\".format(combined_features))\n",
    "print(\"Combined Features Dense Flattened: {}\\n\".format(combined_features_dense))\n",
    "\n",
    "\n",
    "\n",
    "# Reshape the flattened array to (1, 400)\n",
    "combined_features_reshaped = np.reshape(\n",
    "    combined_features_dense, (1, -1))\n",
    "\n",
    "print(\"Combined Features Reshaped FINAL: {}\\n\".format(combined_features_reshaped))\n",
    "print(\"Combined Feature Reshaped FINAL Shape: {}\\n\".format(combined_features_reshaped.shape))\n",
    "\n",
    "predictions = prediction_model.predict(\n",
    "    combined_features_reshaped)\n",
    "print(\"Predictions\", predictions)\n",
    "if ((1-predictions[0][0]) > 0.5):\n",
    "    print(\"Scam detected with probability: {}\".format(\n",
    "        (1-predictions[0][0])))\n",
    "else:\n",
    "    print(\"Normal conversation detected with probability: {}\".format(\n",
    "        predictions[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\SPARK'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession with necessary configurations\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('Spark') \\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .config(\"spark.hadoop.home.dir\", \"H:/HADOOP/\") \\\n",
    "    .config(\"spark.hadoop.conf.dir\", \"H:/HADOOP/etc/hadoop/\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "import sys\n",
    "sys.path.append(\"G:\\Dissertation_Project\")\n",
    "\n",
    "# Get SparkContext from the SparkSession\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.6:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2283ac53e50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|Conversation_ID|Attacker_Helper                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |Victim                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |Conversation_Type|\n",
      "+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "|GT1sURbxgG_0   |[['hi', 'thi', 'is', 'john', 'from', 'the', 'ir', 'you', 'owe', 'us', 'xxxxx', 'in', 'back', 'tax']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |[['im', 'sorri', 'i', 'dont', 'believ', 'you', 'can', 'you', 'provid', 'me', 'with', 'your', 'badg', 'number']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |1                |\n",
      "|GT1sURbxgG_1   |[['hi', 'thi', 'is', 'john', 'from', 'the', 'ir', 'you', 'owe', 'us', 'xxxxx', 'in', 'back', 'tax', 'ye', 'of', 'cours', 'it', 'xxxx']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |[['im', 'sorri', 'i', 'dont', 'believ', 'you', 'can', 'you', 'provid', 'me', 'with', 'your', 'badg', 'number', 'im', 'still', 'not', 'sure', 'can', 'i', 'call', 'you', 'back', 'to', 'verifi', 'thi', 'inform']]                                                                                                                                                                                                                                                                                                                                                                                                                 |1                |\n",
      "|GT1sURbxgG_2   |[['hi', 'thi', 'is', 'john', 'from', 'the', 'ir', 'you', 'owe', 'us', 'xxxxx', 'in', 'back', 'tax', 'ye', 'of', 'cours', 'it', 'xxxx', 'no', 'you', 'can', 'not', 'we', 'need', 'payment', 'immedi', 'or', 'we', 'will', 'send', 'the', 'polic', 'to', 'your', 'hous']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |[['im', 'sorri', 'i', 'dont', 'believ', 'you', 'can', 'you', 'provid', 'me', 'with', 'your', 'badg', 'number', 'im', 'still', 'not', 'sure', 'can', 'i', 'call', 'you', 'back', 'to', 'verifi', 'thi', 'inform', 'i', 'dont', 'think', 'that', 'legal', 'ill', 'be', 'contact', 'the', 'ir', 'directli', 'to', 'confirm', 'thi']]                                                                                                                                                                                                                                                                                                 |1                |\n",
      "|TwaGOeC96w_0   |[['hello', 'thi', 'is', 'xyz', 'bank', 'call', 'may', 'i', 'speak', 'with', 'victim', 'name', 'pleas']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |[['thi', 'is', 'victim', 'name', 'how', 'can', 'i', 'help', 'you']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |0                |\n",
      "|TwaGOeC96w_1   |[['hello', 'thi', 'is', 'xyz', 'bank', 'call', 'may', 'i', 'speak', 'with', 'victim', 'name', 'pleas', 'good', 'morn', 'victim', 'name', 'we', 'just', 'notic', 'some', 'unusu', 'activ', 'on', 'your', 'account', 'and', 'want', 'to', 'verifi', 'a', 'few', 'thing', 'can', 'you', 'confirm', 'your', 'account', 'number', 'for', 'me']]                                                                                                                                                                                                                                                                                                                                                                                                 |[['thi', 'is', 'victim', 'name', 'how', 'can', 'i', 'help', 'you', 'im', 'sorri', 'i', 'dont', 'feel', 'comfort', 'give', 'out', 'my', 'account', 'number', 'on', 'the', 'phone', 'is', 'there', 'anoth', 'way', 'we', 'can', 'verifi', 'my', 'inform']]                                                                                                                                                                                                                                                                                                                                                                          |0                |\n",
      "|TwaGOeC96w_2   |[['hello', 'thi', 'is', 'xyz', 'bank', 'call', 'may', 'i', 'speak', 'with', 'victim', 'name', 'pleas', 'good', 'morn', 'victim', 'name', 'we', 'just', 'notic', 'some', 'unusu', 'activ', 'on', 'your', 'account', 'and', 'want', 'to', 'verifi', 'a', 'few', 'thing', 'can', 'you', 'confirm', 'your', 'account', 'number', 'for', 'me', 'absolut', 'we', 'complet', 'understand', 'your', 'concern', 'can', 'you', 'pleas', 'provid', 'your', 'date', 'of', 'birth', 'and', 'social', 'secur', 'number', 'for', 'verif', 'purpos']]                                                                                                                                                                                                      |[['thi', 'is', 'victim', 'name', 'how', 'can', 'i', 'help', 'you', 'im', 'sorri', 'i', 'dont', 'feel', 'comfort', 'give', 'out', 'my', 'account', 'number', 'on', 'the', 'phone', 'is', 'there', 'anoth', 'way', 'we', 'can', 'verifi', 'my', 'inform', 'im', 'still', 'hesit', 'to', 'provid', 'that', 'inform', 'over', 'the', 'phone', 'can', 'i', 'come', 'into', 'the', 'bank', 'and', 'verifi', 'my', 'inform', 'in', 'person']]                                                                                                                                                                                            |1                |\n",
      "|TwaGOeC96w_3   |[['hello', 'thi', 'is', 'xyz', 'bank', 'call', 'may', 'i', 'speak', 'with', 'victim', 'name', 'pleas', 'good', 'morn', 'victim', 'name', 'we', 'just', 'notic', 'some', 'unusu', 'activ', 'on', 'your', 'account', 'and', 'want', 'to', 'verifi', 'a', 'few', 'thing', 'can', 'you', 'confirm', 'your', 'account', 'number', 'for', 'me', 'absolut', 'we', 'complet', 'understand', 'your', 'concern', 'can', 'you', 'pleas', 'provid', 'your', 'date', 'of', 'birth', 'and', 'social', 'secur', 'number', 'for', 'verif', 'purpos', 'of', 'cours', 'that', 'a', 'great', 'idea', 'our', 'branch', 'hour', 'are', 'xamxpm', 'monday', 'through', 'friday', 'is', 'there', 'a', 'day', 'and', 'time', 'that', 'work', 'best', 'for', 'you']]|[['thi', 'is', 'victim', 'name', 'how', 'can', 'i', 'help', 'you', 'im', 'sorri', 'i', 'dont', 'feel', 'comfort', 'give', 'out', 'my', 'account', 'number', 'on', 'the', 'phone', 'is', 'there', 'anoth', 'way', 'we', 'can', 'verifi', 'my', 'inform', 'im', 'still', 'hesit', 'to', 'provid', 'that', 'inform', 'over', 'the', 'phone', 'can', 'i', 'come', 'into', 'the', 'bank', 'and', 'verifi', 'my', 'inform', 'in', 'person', 'ye', 'i', 'can', 'come', 'in', 'on', 'thursday', 'at', 'around', 'xpm', 'thank', 'you', 'for', 'understand']]                                                                              |0                |\n",
      "|V73ZDCviQL_0   |[['hello', 'sir', 'thi', 'is', 'a', 'call', 'from', 'the', 'ir', 'we', 'have', 'found', 'discrep', 'in', 'your', 'tax', 'file', 'and', 'need', 'to', 'verifi', 'some', 'inform']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |[['ive', 'never', 'had', 'ani', 'issu', 'with', 'my', 'tax', 'befor', 'can', 'you', 'provid', 'me', 'with', 'more', 'specif', 'inform']]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |0                |\n",
      "|V73ZDCviQL_1   |[['hello', 'sir', 'thi', 'is', 'a', 'call', 'from', 'the', 'ir', 'we', 'have', 'found', 'discrep', 'in', 'your', 'tax', 'file', 'and', 'need', 'to', 'verifi', 'some', 'inform', 'ye', 'sir', 'we', 'need', 'your', 'social', 'secur', 'number', 'and', 'bank', 'account', 'detail', 'to', 'verifi', 'the', 'inform']]                                                                                                                                                                                                                                                                                                                                                                                                                     |[['ive', 'never', 'had', 'ani', 'issu', 'with', 'my', 'tax', 'befor', 'can', 'you', 'provid', 'me', 'with', 'more', 'specif', 'inform', 'im', 'sorri', 'but', 'i', 'dont', 'feel', 'comfort', 'share', 'that', 'inform', 'over', 'the', 'phone', 'can', 'you', 'send', 'me', 'an', 'email', 'or', 'mail', 'me', 'a', 'letter', 'instead']]                                                                                                                                                                                                                                                                                        |0                |\n",
      "|V73ZDCviQL_2   |[['hello', 'sir', 'thi', 'is', 'a', 'call', 'from', 'the', 'ir', 'we', 'have', 'found', 'discrep', 'in', 'your', 'tax', 'file', 'and', 'need', 'to', 'verifi', 'some', 'inform', 'ye', 'sir', 'we', 'need', 'your', 'social', 'secur', 'number', 'and', 'bank', 'account', 'detail', 'to', 'verifi', 'the', 'inform', 'there', 'no', 'need', 'to', 'worri', 'sir', 'we', 'are', 'a', 'legitim', 'organ', 'and', 'need', 'thi', 'inform', 'to', 'resolv', 'the', 'issu', 'quickli']]                                                                                                                                                                                                                                                        |[['ive', 'never', 'had', 'ani', 'issu', 'with', 'my', 'tax', 'befor', 'can', 'you', 'provid', 'me', 'with', 'more', 'specif', 'inform', 'im', 'sorri', 'but', 'i', 'dont', 'feel', 'comfort', 'share', 'that', 'inform', 'over', 'the', 'phone', 'can', 'you', 'send', 'me', 'an', 'email', 'or', 'mail', 'me', 'a', 'letter', 'instead', 'i', 'appreci', 'your', 'concern', 'but', 'i', 'still', 'can', 'not', 'provid', 'that', 'inform', 'over', 'the', 'phone', 'can', 'you', 'pleas', 'provid', 'me', 'with', 'a', 'refer', 'number', 'for', 'thi', 'issu', 'so', 'i', 'can', 'verifi', 'it', 'with', 'the', 'ir', 'myself']]|1                |\n",
      "+---------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df = spark.read.csv(\"../Data/Preprocessed_Datasets/DATASET_FINAL_PREPROCESSED.csv\", header=True, inferSchema=True)\n",
    "preprocessed_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Conversation Columns into actual Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Conversation_ID: string (nullable = true)\n",
      " |-- Attacker_Helper: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- Victim: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- Conversation_Type: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.functions import udf\n",
    "import ast\n",
    "\n",
    "# UDF to convert string representation of list to actual list\n",
    "def str_to_array_of_arrays(s):\n",
    "    # Convert the string to a list and then wrap it inside another list\n",
    "    return [ast.literal_eval(s)][0]\n",
    "\n",
    "str_to_array_of_arrays_udf = udf(str_to_array_of_arrays, ArrayType(ArrayType(StringType())))\n",
    "\n",
    "df = preprocessed_df.withColumn(\"Attacker_Helper\", str_to_array_of_arrays_udf(preprocessed_df[\"Attacker_Helper\"])).withColumn(\"Victim\", str_to_array_of_arrays_udf(preprocessed_df[\"Victim\"]))\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the pipeline and transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "from src.CustonTransformers import FlattenTransformer\n",
    "\n",
    "pipeline_model_path = \"./Models/Pipelines/TF-IDF_Pipeline\"\n",
    "\n",
    "pipeline = PipelineModel.load(path=pipeline_model_path)\n",
    "\n",
    "df_assembled = pipeline.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Conversation_ID|Combined_Features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|GT1sURbxgG_2   |(400,[5,7,9,17,20,30,31,35,37,45,60,63,69,82,86,88,95,101,104,121,123,133,137,138,141,168,176,184,187,188,196,205,213,217,221,223,230,245,248,249,250,255,263,266,271,282,288,312,319,330,333,335,337,338,345,346,349,356,360,369,377,385],[0.7602710041204558,1.0595416178484824,0.03978927821076632,0.20213295182460733,0.8960183696964397,1.2009125710293418,2.533139710878957,0.7507810159356075,0.6339166757962966,0.04327461429777342,1.4885946434811228,0.08306085561816683,0.8637791773592514,1.2492861553135577,0.6157012359049555,0.1640443576925002,0.484428710290161,0.6956579923128067,2.219640054338441,0.23971929253447463,2.248092686065181,0.3398213885098024,0.2611947062600467,0.31174074141356994,1.8612699287662964,0.6136404417701671,1.5509955332859213,1.6119487241869617,0.500385283171774,0.22320535004709133,1.2454064220279688,0.5927586033027892,1.881180088725626,0.28610441911540957,0.9926946699318078,1.1704531132944145,1.5939551591389491,1.1006500097763852,1.2629849996717195,1.0900501295079457,0.7578900506147138,1.2778736121654701,0.7543292159917049,0.7001372831168527,4.548042731421221,1.8866796442916647,1.1074247561527109,1.304217587505072,1.0668026420855297,1.6402792308131877,0.6772958180176385,1.4593954887888605,0.7734685562024023,0.4491075637674481,1.8382396814915969,0.7466572987517456,1.0864271475945149,0.37053392517860595,0.41878835406209436,0.5411881295910415,2.647835101333754,2.305095904746907])|\n",
      "+---------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = df_assembled.select('Conversation_ID','Combined_Features')\n",
    "test_df = test_df.filter(test_df['Conversation_ID'] == 'GT1sURbxgG_2').limit(1)\n",
    "test_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of -features_numpy_test- array --> (1, 400)\n",
      "[[0.         0.         0.         0.         0.         0.760271\n",
      "  0.         1.05954162 0.         0.03978928 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20213295\n",
      "  0.         0.         0.89601837 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.20091257 2.53313971 0.         0.         0.         0.75078102\n",
      "  0.         0.63391668 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.04327461 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.48859464 0.         0.         0.08306086 0.         0.\n",
      "  0.         0.         0.         0.86377918 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.24928616 0.\n",
      "  0.         0.         0.61570124 0.         0.16404436 0.\n",
      "  0.         0.         0.         0.         0.         0.48442871\n",
      "  0.         0.         0.         0.         0.         0.69565799\n",
      "  0.         0.         2.21964005 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.23971929 0.         2.24809269 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.33982139 0.         0.         0.         0.26119471\n",
      "  0.31174074 0.         0.         1.86126993 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.61364044 0.         0.         0.         0.         0.\n",
      "  0.         0.         1.55099553 0.         0.         0.\n",
      "  0.         0.         0.         0.         1.61194872 0.\n",
      "  0.         0.50038528 0.22320535 0.         0.         0.\n",
      "  0.         0.         0.         0.         1.24540642 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.5927586  0.         0.         0.         0.\n",
      "  0.         0.         0.         1.88118009 0.         0.\n",
      "  0.         0.28610442 0.         0.         0.         0.99269467\n",
      "  0.         1.17045311 0.         0.         0.         0.\n",
      "  0.         0.         1.59395516 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         1.10065001\n",
      "  0.         0.         1.262985   1.09005013 0.75789005 0.\n",
      "  0.         0.         0.         1.27787361 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.75432922\n",
      "  0.         0.         0.70013728 0.         0.         0.\n",
      "  0.         4.54804273 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.88667964 0.         0.         0.         0.         0.\n",
      "  1.10742476 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.30421759 0.         0.         0.         0.         0.\n",
      "  0.         1.06680264 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.64027923 0.         0.         0.67729582 0.         1.45939549\n",
      "  0.         0.77346856 0.44910756 0.         0.         0.\n",
      "  0.         0.         0.         1.83823968 0.7466573  0.\n",
      "  0.         1.08642715 0.         0.         0.         0.\n",
      "  0.         0.         0.37053393 0.         0.         0.\n",
      "  0.41878835 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.54118813 0.         0.\n",
      "  0.         0.         0.         0.         0.         2.6478351\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         2.3050959  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "features = test_df.select('Combined_Features').rdd.map(lambda row: row.Combined_Features).collect()\n",
    "features_numpy_test = np.array(features)\n",
    "\n",
    "print(\"Shape of -features_numpy_test- array --> {}\".format(features_numpy_test.shape))\n",
    "print(features_numpy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[0.9926143]]\n"
     ]
    }
   ],
   "source": [
    "predictions = prediction_model.predict(features_numpy_test)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
